{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Action1：针对Delicious数据集，对SimpleTagBased算法进行改进（使用NormTagBased、TagBased-TFIDF算法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用SimpleTagBased算法对Delicious2K数据进行推荐\n",
    "# 原始数据集：https://grouplens.org/datasets/hetrec-2011/\n",
    "# 数据格式：userID     bookmarkID     tagID     timestamp\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"./user_taggedbookmarks-timestamps.dat\"\n",
    "# 字典类型，保存了user对item的tag，即{userid: {item1:[tag1, tag2], ...}}\n",
    "records = {}\n",
    "# 训练集，测试集\n",
    "train_data = dict()\n",
    "test_data = dict()\n",
    "# 用户标签，商品标签\n",
    "user_tags = dict()\n",
    "tag_items = dict()\n",
    "user_items = dict()\n",
    "\n",
    "# 增加一些dict\n",
    "item_tags, tag_users, item_users = dict(), dict(), dict()\n",
    "\n",
    "# 使用测试集，计算准确率和召回率\n",
    "def precisionAndRecall(N):\n",
    "    hit = 0\n",
    "    h_recall = 0\n",
    "    h_precision = 0\n",
    "    for user, items in test_data.items():\n",
    "        if user not in train_data:\n",
    "            continue\n",
    "        # 获取Top-N推荐列表\n",
    "        rank = recommend(user, N)\n",
    "        for item, rui in rank:\n",
    "            if item in items:\n",
    "                hit = hit + 1\n",
    "        h_recall = h_recall + len(items)\n",
    "        h_precision = h_precision + N\n",
    "    # print('一共命中 %d 个, 一共推荐 %d 个, 用户设置tag总数 %d 个' %(hit, h_precision, h_recall))\n",
    "    # 返回准确率 和 召回率\n",
    "    return (hit / (h_precision * 1.0)), (hit / (h_recall * 1.0))\n",
    "\n",
    "\n",
    "# 对用户user推荐Top-N\n",
    "def recommend(user, N):\n",
    "    recommend_items = dict()\n",
    "    # 对Item进行打分，分数为所有的（用户对某标签使用的次数 wut, 乘以 商品被打上相同标签的次数 wti）之和\n",
    "    tagged_items = user_items[user]\n",
    "    for tag, wut in user_tags[user].items():\n",
    "        # print(self.user_tags[user].items())\n",
    "        for item, wti in tag_items[tag].items():\n",
    "            if item in tagged_items:\n",
    "                continue\n",
    "            if norm_type == \"NormTagBased\":\n",
    "            # NormTagBased-1算法\n",
    "                norm = len(tag_users[tag].items()) * len(user_items[user].items())\n",
    "            # TagBased-ID算法\n",
    "            elif norm_type == \"TagBased-TFIDF\":\n",
    "                norm = math.log(len(tag_users[tag].items())+1)\n",
    "            # print('wut = %s, wti = %s' %(wut, wti))\n",
    "            if item not in recommend_items:\n",
    "                recommend_items[item] = wut * wti /norm\n",
    "            else:\n",
    "                recommend_items[item] = recommend_items[item] + wut * wti / norm\n",
    "    return sorted(recommend_items.items(), key=operator.itemgetter(1), reverse=True)[0:N]\n",
    "\n",
    "\n",
    "# 使用测试集，对推荐结果进行评估\n",
    "def testRecommend():\n",
    "    print(\"推荐结果评估\")\n",
    "    print(\"%3s %10s %10s\" % ('N', \"精确率\", '召回率'))\n",
    "    for n in [5, 10, 20, 40, 60, 80, 100]:\n",
    "        precision, recall = precisionAndRecall(n)\n",
    "        print(\"%3d %10.3f%% %10.3f%%\" % (n, precision * 100, recall * 100))\n",
    "\n",
    "\n",
    "# 数据加载\n",
    "def load_data():\n",
    "    print(\"开始数据加载...\")\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    for i in range(len(df)):\n",
    "        uid = df['userID'][i]\n",
    "        iid = df['bookmarkID'][i]\n",
    "        tag = df['tagID'][i]\n",
    "        # 键不存在时，设置默认值{}\n",
    "        records.setdefault(uid, {})\n",
    "        records[uid].setdefault(iid, [])\n",
    "        records[uid][iid].append(tag)\n",
    "    print(\"数据集大小为 %d.\" % (len(df)))\n",
    "    print(\"设置tag的人数 %d.\" % (len(records)))\n",
    "    print(\"数据加载完成\\n\")\n",
    "\n",
    "\n",
    "# 将数据集拆分为训练集和测试集\n",
    "def train_test_split(ratio, seed=100):\n",
    "    random.seed(seed)\n",
    "    for u in records.keys():\n",
    "        for i in records[u].keys():\n",
    "            # ratio比例设置为测试集\n",
    "            if random.random() < ratio:\n",
    "                test_data.setdefault(u, {})\n",
    "                test_data[u].setdefault(i, [])\n",
    "                for t in records[u][i]:\n",
    "                    test_data[u][i].append(t)\n",
    "            else:\n",
    "                train_data.setdefault(u, {})\n",
    "                train_data[u].setdefault(i, [])\n",
    "                for t in records[u][i]:\n",
    "                    train_data[u][i].append(t)\n",
    "    print(\"训练集样本数 %d, 测试集样本数 %d\" % (len(train_data), len(test_data)))\n",
    "\n",
    "\n",
    "# 设置矩阵 mat[index, item] = 1\n",
    "def addValueToMat(mat, index, item, value=1):\n",
    "    if index not in mat:\n",
    "        mat.setdefault(index, {})\n",
    "        mat[index].setdefault(item, value)\n",
    "    else:\n",
    "        if item not in mat[index]:\n",
    "            mat[index][item] = value\n",
    "        else:\n",
    "            mat[index][item] += value\n",
    "\n",
    "\n",
    "# 使用训练集，初始化user_tags, tag_items, user_items\n",
    "def initStat():\n",
    "    records = train_data\n",
    "    for u, items in records.items():\n",
    "        for i, tags in items.items():\n",
    "            for tag in tags:\n",
    "                # print tag\n",
    "                # 用户和tag的关系\n",
    "                addValueToMat(user_tags, u, tag, 1)\n",
    "                # tag和item的关系\n",
    "                addValueToMat(tag_items, tag, i, 1)\n",
    "                # 用户和item的关系\n",
    "                addValueToMat(user_items, u, i, 1)\n",
    "                # item 和 tag关系\n",
    "                addValueToMat(item_tags, i, tag, 1)\n",
    "                #tag和用户的关系\n",
    "                addValueToMat(tag_users, tag, u, 1)\n",
    "                #items和用户的关系\n",
    "                addValueToMat(item_users, i, u, 1)\n",
    "    print(\"user_tags, tag_items, user_items初始化完成.\")\n",
    "    print(\"user_tags大小 %d, tag_items大小 %d, user_items大小 %d\" % (len(user_tags), len(tag_items), len(user_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始数据加载...\n",
      "数据集大小为 437593.\n",
      "设置tag的人数 1867.\n",
      "数据加载完成\n",
      "\n",
      "训练集样本数 1860, 测试集样本数 1793\n",
      "user_tags, tag_items, user_items初始化完成.\n",
      "user_tags大小 1860, tag_items大小 36884, user_items大小 1860\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 数据加载\n",
    "load_data()\n",
    "# 训练集，测试集拆分，20%测试集\n",
    "train_test_split(0.2)\n",
    "initStat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 使用NormTagBased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推荐结果评估\n",
      "  N        精确率        召回率\n",
      "  5      0.907%      0.388%\n",
      " 10      0.638%      0.546%\n",
      " 20      0.507%      0.868%\n",
      " 40      0.356%      1.218%\n",
      " 60      0.287%      1.476%\n",
      " 80      0.255%      1.750%\n",
      "100      0.241%      2.061%\n",
      "Wall time: 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "norm_type = \"NormTagBased\"\n",
    "testRecommend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 使用TagBased-TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推荐结果评估\n",
      "  N        精确率        召回率\n",
      "  5      1.008%      0.431%\n",
      " 10      0.761%      0.652%\n",
      " 20      0.549%      0.940%\n",
      " 40      0.402%      1.376%\n",
      " 60      0.328%      1.687%\n",
      " 80      0.297%      2.033%\n",
      "100      0.269%      2.306%\n",
      "Wall time: 6min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "norm_type = \"TagBased-TFIDF\"\n",
    "testRecommend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Action2：对Titanic数据进行清洗，使用之前介绍过的10种模型中的至少2种（包括TPOT）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看数据信息：列名、非空个数、类型等\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "------------------------------\n",
      "查看数据摘要\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "------------------------------\n",
      "查看离散数据分布\n",
      "                        Name   Sex Ticket        Cabin Embarked\n",
      "count                    891   891    891          204      889\n",
      "unique                   891     2    681          147        3\n",
      "top     Zabour, Miss. Hileni  male   1601  C23 C25 C27        S\n",
      "freq                       1   577      7            4      644\n",
      "------------------------------\n",
      "查看前5条数据\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "------------------------------\n",
      "查看后5条数据\n",
      "     PassengerId  Survived  Pclass                                      Name  \\\n",
      "886          887         0       2                     Montvila, Rev. Juozas   \n",
      "887          888         1       1              Graham, Miss. Margaret Edith   \n",
      "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "889          890         1       1                     Behr, Mr. Karl Howell   \n",
      "890          891         0       3                       Dooley, Mr. Patrick   \n",
      "\n",
      "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
      "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
      "887  female  19.0      0      0      112053  30.00   B42        S  \n",
      "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
      "889    male  26.0      0      0      111369  30.00  C148        C  \n",
      "890    male  32.0      0      0      370376   7.75   NaN        Q  \n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "特征值\n",
      "     Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
      "0         3    male  22.000000      1      0   7.2500        S\n",
      "1         1  female  38.000000      1      0  71.2833        C\n",
      "2         3  female  26.000000      0      0   7.9250        S\n",
      "3         1  female  35.000000      1      0  53.1000        S\n",
      "4         3    male  35.000000      0      0   8.0500        S\n",
      "..      ...     ...        ...    ...    ...      ...      ...\n",
      "886       2    male  27.000000      0      0  13.0000        S\n",
      "887       1  female  19.000000      0      0  30.0000        S\n",
      "888       3  female  29.699118      1      2  23.4500        S\n",
      "889       1    male  26.000000      0      0  30.0000        C\n",
      "890       3    male  32.000000      0      0   7.7500        Q\n",
      "\n",
      "[891 rows x 7 columns]\n",
      "['Age', 'Embarked=C', 'Embarked=Q', 'Embarked=S', 'Fare', 'Parch', 'Pclass', 'Sex=female', 'Sex=male', 'SibSp']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# 数据加载\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "test_data = pd.read_csv('./test.csv')\n",
    "# 数据探索\n",
    "# 查看train_data信息\n",
    "#pd.set_option('display.max_columns', None) #显示所有列\n",
    "print('查看数据信息：列名、非空个数、类型等')\n",
    "print(train_data.info())\n",
    "print('-'*30)\n",
    "print('查看数据摘要')\n",
    "print(train_data.describe())\n",
    "print('-'*30)\n",
    "print('查看离散数据分布')\n",
    "print(train_data.describe(include=['O']))\n",
    "print('-'*30)\n",
    "print('查看前5条数据')\n",
    "print(train_data.head())\n",
    "print('-'*30)\n",
    "print('查看后5条数据')\n",
    "print(train_data.tail())\n",
    "\n",
    "# 使用平均年龄来填充年龄中的nan值\n",
    "train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)\n",
    "test_data['Age'].fillna(test_data['Age'].mean(),inplace=True)\n",
    "# 使用票价的均值填充票价中的nan值\n",
    "train_data['Fare'].fillna(train_data['Fare'].mean(), inplace=True)\n",
    "test_data['Fare'].fillna(test_data['Fare'].mean(),inplace=True)\n",
    "\n",
    "print(train_data['Embarked'].value_counts())\n",
    "# 使用登录最多的港口来填充登录港口的nan值\n",
    "train_data['Embarked'].fillna('S', inplace=True)\n",
    "test_data['Embarked'].fillna('S',inplace=True)\n",
    "# 特征选择\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "train_features = train_data[features]\n",
    "train_labels = train_data['Survived']\n",
    "test_features = test_data[features]\n",
    "print('特征值')\n",
    "print(train_features)\n",
    "\n",
    "dvec=DictVectorizer(sparse=False)\n",
    "train_features=dvec.fit_transform(train_features.to_dict(orient='record'))\n",
    "print(dvec.feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 使用决策树预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树score准确率为 0.9820\n",
      "决策树cross_val_score准确率为 0.7778\n"
     ]
    }
   ],
   "source": [
    "# 构造ID3决策树\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "# 决策树训练\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "test_features=dvec.transform(test_features.to_dict(orient='record'))\n",
    "# 决策树预测\n",
    "pred_labels = clf.predict(test_features)\n",
    "\n",
    "# 得到决策树准确率(基于训练集)\n",
    "acc_decision_tree = round(clf.score(train_features, train_labels), 6)\n",
    "print(u'决策树score准确率为 %.4lf' % acc_decision_tree)\n",
    "\n",
    "# 使用K折交叉验证 统计决策树准确率\n",
    "print(u'决策树cross_val_score准确率为 %.4lf' % np.mean(cross_val_score(clf, train_features, train_labels, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2）使用逻辑回归进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "逻辑回归score准确率为 0.8036\n",
      "逻辑回归cross_val_score准确率为 0.7946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='liblinear', C=1)\n",
    "lr.fit(train_features, train_labels)\n",
    "pred_labels = lr.predict(test_features)\n",
    "acc_lr = round(lr.score(train_features, train_labels), 6)\n",
    "print(u'逻辑回归score准确率为 %.4lf' % acc_lr)\n",
    "# 使用K折交叉验证 统计决策树准确率\n",
    "print(u'逻辑回归cross_val_score准确率为 %.4lf' % np.mean(cross_val_score(lr, train_features, train_labels, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 使用TPOP工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LGB\\Anaconda3\\envs\\lgb_02\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=120.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8226853304877283\n",
      "Generation 2 - Current best internal CV score: 0.8293955181721172\n",
      "Generation 3 - Current best internal CV score: 0.8293955181721172\n",
      "Generation 4 - Current best internal CV score: 0.8361747536250078\n",
      "Generation 5 - Current best internal CV score: 0.8395455401418618\n",
      "Best pipeline: GradientBoostingClassifier(input_matrix, learning_rate=0.01, max_depth=9, max_features=0.9000000000000001, min_samples_leaf=5, min_samples_split=5, n_estimators=100, subsample=0.6500000000000001)\n",
      "tpop score准确率为 0.8878\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2)\n",
    "tpot.fit(train_features, train_labels)\n",
    "acc_tpop = tpot.score(train_features, train_labels)\n",
    "print(u'tpop score准确率为 %.4lf' % acc_tpop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('tpot_titanic_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgb_02",
   "language": "python",
   "name": "lgb_02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
